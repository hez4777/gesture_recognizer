{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjUiicdZ3wT5cTrO8u4tfE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hez4777/gesture_recognizer/blob/main/gesture_test_old.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM1IIS0gNb_O",
        "outputId": "f97b771c-0d6c-4a44-b6c1-c23ae81a2391",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.6)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.21 sounddevice-0.5.1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install mediapipe scikit-learn seaborn\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from PIL import Image\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def list_gesture_folders(dataset_path: str) -> List[str]:\n",
        "    \"\"\"List all gesture subfolders in the dataset directory.\"\"\"\n",
        "    return [d for d in os.listdir(dataset_path)\n",
        "            if os.path.isdir(os.path.join(dataset_path, d))]\n",
        "\n",
        "def sample_images_from_folders(dataset_path: str, folders: List[str],\n",
        "                              sample_ratio: float = 0.2) -> Dict[str, List[str]]:\n",
        "    \"\"\"Sample a percentage of images from each gesture folder.\"\"\"\n",
        "    sampled_images = {}\n",
        "\n",
        "    for folder in folders:\n",
        "        folder_path = os.path.join(dataset_path, folder)\n",
        "        image_paths = glob.glob(os.path.join(folder_path, \"*.jpg\")) + \\\n",
        "                     glob.glob(os.path.join(folder_path, \"*.jpeg\")) + \\\n",
        "                     glob.glob(os.path.join(folder_path, \"*.png\"))\n",
        "\n",
        "        num_samples = max(1, int(len(image_paths) * sample_ratio))\n",
        "        sampled = random.sample(image_paths, num_samples)\n",
        "        sampled_images[folder] = sampled\n",
        "\n",
        "        print(f\"Sampled {len(sampled)} images from {folder} (total: {len(image_paths)})\")\n",
        "\n",
        "    return sampled_images\n",
        "\n",
        "def load_gesture_recognizer(model_path: str) -> vision.GestureRecognizer:\n",
        "    \"\"\"Load the gesture recognizer model.\"\"\"\n",
        "    base_options = python.BaseOptions(model_asset_path=model_path)\n",
        "    options = vision.GestureRecognizerOptions(\n",
        "        base_options=base_options,\n",
        "        running_mode=vision.RunningMode.IMAGE,\n",
        "        num_hands=1\n",
        "    )\n",
        "    return vision.GestureRecognizer.create_from_options(options)\n",
        "\n",
        "def process_image(image_path: str, recognizer: vision.GestureRecognizer) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Process a single image and return the recognized gesture.\n",
        "    Returns None if no hand is detected.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        image = mp.Image.create_from_file(image_path)\n",
        "        recognition_result = recognizer.recognize(image)\n",
        "\n",
        "        if recognition_result.gestures and len(recognition_result.gestures) > 0:\n",
        "            return recognition_result.gestures[0][0].category_name\n",
        "        else:\n",
        "            # No gesture detected\n",
        "            return \"None\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "        return \"None\"\n",
        "\n",
        "def evaluate_gesture_recognizer(dataset_path: str, model_path: str,\n",
        "                              sample_ratio: float = 0.2) -> Tuple[np.ndarray, List[str], pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Evaluate the gesture recognizer on sampled images from each gesture folder.\n",
        "    Returns confusion matrix, class names, and a DataFrame with detailed results.\n",
        "    \"\"\"\n",
        "    gesture_folders = list_gesture_folders(dataset_path)\n",
        "    print(f\"Found {len(gesture_folders)} gesture classes: {gesture_folders}\")\n",
        "\n",
        "    sampled_images = sample_images_from_folders(dataset_path, gesture_folders, sample_ratio)\n",
        "\n",
        "    recognizer = load_gesture_recognizer(model_path)\n",
        "\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "    results_data = []\n",
        "\n",
        "    for gesture_class, image_paths in sampled_images.items():\n",
        "        for image_path in image_paths:\n",
        "            true_label = gesture_class\n",
        "\n",
        "            predicted_label = process_image(image_path, recognizer)\n",
        "\n",
        "            true_labels.append(true_label)\n",
        "            predicted_labels.append(predicted_label)\n",
        "            results_data.append({\n",
        "                \"image_path\": image_path,\n",
        "                \"true_label\": true_label,\n",
        "                \"predicted_label\": predicted_label\n",
        "            })\n",
        "\n",
        "            print(f\"Image: {os.path.basename(image_path)}, True: {true_label}, Predicted: {predicted_label}\")\n",
        "\n",
        "    # confusion matrix\n",
        "    all_classes = gesture_folders.copy()\n",
        "    if \"None\" in predicted_labels and \"None\" not in all_classes:\n",
        "        all_classes.append(\"None\")\n",
        "\n",
        "    conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=all_classes)\n",
        "\n",
        "    results_df = pd.DataFrame(results_data)\n",
        "\n",
        "    return conf_matrix, all_classes, results_df\n",
        "\n",
        "def plot_confusion_matrix(conf_matrix: np.ndarray, class_names: List[str], save_path: Optional[str] = None,\n",
        "                      normalize: bool = False, precision: bool = False):\n",
        "    \"\"\"\n",
        "    Plot and optionally save the confusion matrix.\n",
        "\n",
        "    Args:\n",
        "        conf_matrix: The confusion matrix to plot\n",
        "        class_names: List of class names\n",
        "        save_path: Optional path to save the figure\n",
        "        normalize: Whether to normalize the matrix (to 1 or 100%)\n",
        "        precision: If True, normalize by predicted (column); if False, normalize by actual (row)\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    cm_display = conf_matrix.copy().astype(float)\n",
        "\n",
        "    if normalize:\n",
        "        if precision:\n",
        "            # Normalize by column (predicted) for precision matrix\n",
        "            col_sums = cm_display.sum(axis=0)\n",
        "            col_sums[col_sums == 0] = 1e-10  # Avoid division by zero\n",
        "            cm_display = cm_display / col_sums[np.newaxis, :]\n",
        "            title = 'Normalized Precision Confusion Matrix'\n",
        "            fmt = '.3f'\n",
        "        else:\n",
        "            # Normalize by row (true) for recall matrix\n",
        "            row_sums = cm_display.sum(axis=1)\n",
        "            row_sums[row_sums == 0] = 1e-10  # Avoid division by zero\n",
        "            cm_display = cm_display / row_sums[:, np.newaxis]\n",
        "            title = 'Normalized Recall Confusion Matrix'\n",
        "            fmt = '.3f'\n",
        "    else:\n",
        "        title = 'Gesture Recognition Confusion Matrix'\n",
        "        fmt = 'g'  # 'g' format works for both integers and floats\n",
        "\n",
        "    sns.heatmap(cm_display, annot=True, fmt=fmt, cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(title)\n",
        "\n",
        "    if save_path:\n",
        "        if normalize:\n",
        "            base, ext = os.path.splitext(save_path)\n",
        "            if precision:\n",
        "                save_path = f\"{base}_precision_norm{ext}\"\n",
        "            else:\n",
        "                save_path = f\"{base}_recall_norm{ext}\"\n",
        "\n",
        "        plt.savefig(save_path, bbox_inches='tight')\n",
        "        print(f\"Confusion matrix saved to {save_path}\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NllWSeGpNovb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = '/content/drive/MyDrive/gesture/gesture_data/dataset_combined'\n",
        "MODEL_PATH = '/content/drive/MyDrive/gesture/model/gesture_recognizer_ver2.task'\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/gesture/gesture_results'\n",
        "SAMPLE_RATIO = 0.2\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "BHrJ19V9NslH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}